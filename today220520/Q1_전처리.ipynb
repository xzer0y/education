{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98fd554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec46f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_table('ck_data1.txt',names=['y','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de1837bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_w=set(['은','는','이','가','를','들','에게','의','을','도','으로','만','라서','하다'])#불용어 정의\n",
    "#s_w.add(불용어 추가문자열)#추가할 불용어는 add를 이용하여 입력\n",
    "okt=Okt()#형태소 분석기(자율)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65204e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()#결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c307a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99892, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].nunique(), data['y'].nunique()#중복확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e629e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp/ipykernel_16304/3642056730.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_X']=data.X.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','')#한글외 정리\n",
      "C:\\Users\\student\\AppData\\Local\\Temp/ipykernel_16304/3642056730.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_X']=data.clean_X.str.replace('^ +','')#공백 시작문자 정리\n"
     ]
    }
   ],
   "source": [
    "data=data.drop_duplicates(subset=['X'])#중복제거\n",
    "data['clean_X']=data.X.str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','')#한글외 정리 \n",
    "data['clean_X']=data.clean_X.str.replace('^ +','')#공백 시작문자 정리\n",
    "data['clean_X']=data.clean_X.replace('',np.nan) #공백 NaN화\n",
    "data=data.dropna(how='any') #NaN데이터 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99fe9ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 99892/99892 [02:54<00:00, 572.86it/s]\n"
     ]
    }
   ],
   "source": [
    "okt=Okt()\n",
    "from tqdm import tqdm \n",
    "X_data=[] \n",
    "for i in tqdm(data['clean_X']): \n",
    "    tk_d=okt.morphs(i) \n",
    "    end_d=[w for w in tk_d if not w in s_w]#불용어 처리 \n",
    "    X_data.append(' '.join(end_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6deab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y_name']=data['y']#정답 이름 기록\n",
    "data['encoder_y']=LabelEncoder().fit_transform(data['y'])#정답 숫자화\n",
    "data['categorical_y']=list(to_categorical(data['encoder_y']))#다중 정답을 위한 희소행렬화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58cd5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.array(data['encoder_y'])#이진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e5c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X_data)#입력정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe8c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data,test_x,y_data,test_y = train_test_split(X,Y,test_size=0.3,random_state=0,stratify = Y)#태스트데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54914e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,val_x,train_y,val_y = train_test_split(x_data,y_data,test_size=0.2,random_state=0,stratify = y_data)#학습, 검증 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f96fdab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(train_x)#문서의 단어수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c59cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len([d for d in sorted(list(tk.word_counts.items()),key=lambda x:x[1]) if d[1]>4])+1#4번이하 입력단어 정리시 길이확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "883d09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer(n)#고정된 단어수로 정리\n",
    "token.fit_on_texts(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7087071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_train_x=token.texts_to_sequences(train_x)\n",
    "token_test_x=token.texts_to_sequences(test_x)\n",
    "token_val_x=token.texts_to_sequences(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88192074",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(token_train_x) if len(sentence) < 1]#빈 문장 위치 정보 확인\n",
    "drop_test = [index for index, sentence in enumerate(token_test_x) if len(sentence) < 1]#빈 문장 위치 정보 확인\n",
    "drop_val = [index for index, sentence in enumerate(token_val_x) if len(sentence) < 1]#빈 문장 위치 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bb7c073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "token_train_x = np.delete(token_train_x, drop_train, axis=0)#빈 문장 정리\n",
    "train_y = np.delete(train_y, drop_train, axis=0)#빈 문장 정리\n",
    "token_test_x = np.delete(token_test_x, drop_test, axis=0)#빈 문장 정리\n",
    "test_y = np.delete(test_y, drop_test, axis=0)#빈 문장 정리\n",
    "token_val_x = np.delete(token_val_x, drop_val, axis=0)#빈 문장 정리\n",
    "val_y = np.delete(val_y, drop_val, axis=0)#빈 문장 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "788ca907",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_l=len(pad_sequences(token_train_x)[0])#문장 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2da5c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = pad_sequences(token_train_x,maxlen=w_l)#동일 문장길이화\n",
    "test_inputs = pad_sequences(token_test_x,maxlen=w_l)#동일 문장길이화\n",
    "val_inputs = pad_sequences(token_val_x,maxlen=w_l)#동일 문장길이화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8a7604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs=train_y#출력정리\n",
    "test_outputs=test_y#출력정리\n",
    "val_outputs=val_y#출력정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c4ed1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "전처리_된_데이터={}\n",
    "전처리_된_데이터['학습_데이터']=train_inputs\n",
    "전처리_된_데이터['학습_결과']=train_outputs\n",
    "전처리_된_데이터['태스트_데이터']=test_inputs\n",
    "전처리_된_데이터['태스트_결과']=test_outputs\n",
    "전처리_된_데이터['검증_데이터']=val_inputs\n",
    "전처리_된_데이터['검증_결과']=val_outputs\n",
    "전처리_된_데이터['토큰']=token\n",
    "전처리_된_데이터['단어수']=n\n",
    "전처리_된_데이터['불용어']=s_w\n",
    "전처리_된_데이터['입력길이']=w_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3aafa991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['학습_데이터', '학습_결과', '태스트_데이터', '태스트_결과', '검증_데이터', '검증_결과', '토큰', '단어수', '불용어', '입력길이'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "전처리_된_데이터.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7eee503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(전처리_된_데이터, fw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
