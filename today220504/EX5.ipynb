{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20512a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01466e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c91381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['barber', 'person'],\n",
       " ['barber', 'good', 'person'],\n",
       " ['barber', 'huge', 'person'],\n",
       " ['knew', 'secret'],\n",
       " ['secret', 'kept', 'huge', 'secret'],\n",
       " ['huge', 'secret'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'secret'],\n",
       " ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
       " ['barber', 'went', 'huge', 'mountain']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "문장_토큰화_리스트=sent_tokenize(text)\n",
    "단어_모음={}\n",
    "pr_data=[]\n",
    "불용성단어 = set(stopwords.words('english'))\n",
    "for 문장 in 문장_토큰화_리스트:\n",
    "    단어_토큰화_리스트=word_tokenize(문장)#단어 토큰화\n",
    "    l=[]\n",
    "    for 단어 in 단어_토큰화_리스트:\n",
    "        소문자화_된_단어=단어.lower()\n",
    "        if 소문자화_된_단어 not in 불용성단어:\n",
    "            if len(소문자화_된_단어)>2:#단어수 2이하 제거\n",
    "                l.append(소문자화_된_단어)\n",
    "                if 소문자화_된_단어 not in 단어_모음:\n",
    "                    단어_모음[소문자화_된_단어]=0\n",
    "                단어_모음[소문자화_된_단어]+=1\n",
    "    pr_data.append(l)\n",
    "pr_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb1713c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 8, 5],\n",
       " [1, 3, 5],\n",
       " [9, 2],\n",
       " [2, 4, 3, 2],\n",
       " [3, 2],\n",
       " [1, 4, 6],\n",
       " [1, 4, 6],\n",
       " [1, 4, 2],\n",
       " [7, 7, 3, 2, 10, 1, 11],\n",
       " [1, 12, 3, 13]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(pr_data)\n",
    "encoded = tk.texts_to_sequences(pr_data)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f30ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_l=max(len(x)for x in encoded)\n",
    "max_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8706833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0,  0,  0],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0,  0,  0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in encoded:\n",
    "    while len(i)<max_l:\n",
    "        i.append(0)\n",
    "data=np.array(encoded)     \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17edf30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 8, 5],\n",
       " [1, 3, 5],\n",
       " [9, 2],\n",
       " [2, 4, 3, 2],\n",
       " [3, 2],\n",
       " [1, 4, 6],\n",
       " [1, 4, 6],\n",
       " [1, 4, 2],\n",
       " [7, 7, 3, 2, 10, 1, 11],\n",
       " [1, 12, 3, 13]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(pr_data)\n",
    "encoded = tk.texts_to_sequences(pr_data)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b71e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0,  0,  0],\n",
       "       [ 3,  2,  0,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13,  0,  0,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_data=pad_sequences(encoded,padding='post')\n",
    "end_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168d274e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5,  0,  0,  0],\n",
       "       [ 1,  8,  5,  0,  0],\n",
       "       [ 1,  3,  5,  0,  0],\n",
       "       [ 9,  2,  0,  0,  0],\n",
       "       [ 2,  4,  3,  2,  0],\n",
       "       [ 3,  2,  0,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  6,  0,  0],\n",
       "       [ 1,  4,  2,  0,  0],\n",
       "       [ 7,  7,  3,  2, 10],\n",
       "       [ 1, 12,  3, 13,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_data=pad_sequences(encoded,padding='post',truncating='post',maxlen=5)\n",
    "end_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d9d80b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5, 14, 14, 14, 14, 14],\n",
       "       [ 1,  8,  5, 14, 14, 14, 14],\n",
       "       [ 1,  3,  5, 14, 14, 14, 14],\n",
       "       [ 9,  2, 14, 14, 14, 14, 14],\n",
       "       [ 2,  4,  3,  2, 14, 14, 14],\n",
       "       [ 3,  2, 14, 14, 14, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14, 14, 14],\n",
       "       [ 1,  4,  2, 14, 14, 14, 14],\n",
       "       [ 7,  7,  3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13, 14, 14, 14]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=len(tk.word_index)+1\n",
    "end_data=pad_sequences(encoded,padding='post',truncating='post',value=v)\n",
    "end_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
